{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e4ad967",
   "metadata": {},
   "source": [
    "- input: PDF file\n",
    "- output: Vector DB representation\n",
    "\n",
    "Steps:\n",
    "1. Load & Parse PDF\n",
    "2. Text splitting\n",
    "3. Embedding\n",
    "4. Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a3ae1",
   "metadata": {},
   "source": [
    "## 0. Install Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ab23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install arxiv\n",
    "%pip install langchain\n",
    "%pip install pypdf\n",
    "%pip install langchain_community\n",
    "%pip install cohere\n",
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9583fda",
   "metadata": {},
   "source": [
    "## 1. PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c17fc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheha\\AppData\\Local\\Temp\\ipykernel_11540\\2065310362.py:13: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  paper = next(search.results())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 2510.18234 to paper.pdf\n"
     ]
    }
   ],
   "source": [
    "# PDF File sample\n",
    "import arxiv\n",
    "\n",
    "def download_arxiv_doi(doi, save_path=\"paper.pdf\"):\n",
    "    '''\n",
    "    download only arxiv papers\n",
    "    '''\n",
    "    if not doi.startswith(\"10.48550/arXiv.\"):\n",
    "        raise Exception(\"Not an arXiv DOI.\")\n",
    "    \n",
    "    arxiv_id = doi.split(\"arXiv.\")[-1]\n",
    "    search = arxiv.Search(id_list=[arxiv_id])\n",
    "    paper = next(search.results())\n",
    "    paper.download_pdf(filename=save_path)\n",
    "    print(f\"Downloaded {arxiv_id} to {save_path}\")\n",
    "\n",
    "# Example:\n",
    "download_arxiv_doi(\"10.48550/arXiv.2510.18234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f244138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from docling.datamodel.accelerator_options import AcceleratorDevice, AcceleratorOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling_core.types.doc.document import PictureItem\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from pathlib import Path\n",
    "\n",
    "class ArixParse:\n",
    "    def __init__(self, pdf_path: str):\n",
    "        self.path = pdf_path\n",
    "\n",
    "        accelerator_options = AcceleratorOptions(\n",
    "            num_threads=8, device=AcceleratorDevice.CUDA\n",
    "        )\n",
    "        self.pipeline_options = PdfPipelineOptions()\n",
    "        self.pipeline_options.accelerator_options = accelerator_options\n",
    "\n",
    "        self.pipeline_options.do_ocr = False\n",
    "        self.pipeline_options.do_table_structure = True\n",
    "        self.pipeline_options.ocr_options.lang = [\"en\"]\n",
    "        self.pipeline_options.images_scale = 2.0\n",
    "        self.pipeline_options.generate_page_images = False\n",
    "        self.pipeline_options.generate_picture_images = True\n",
    "        self.converter = DocumentConverter(\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(pipeline_options=self.pipeline_options)\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def parse(self):\n",
    "        return self.converter.convert(self.path).document\n",
    "\n",
    "\n",
    "def parsePDF(path:str, outputdir, withImages = False):\n",
    "    \"\"\" takes PDF file path and returns PDF parsed pages text with metadata\"\"\"\n",
    "    from langchain_community.document_loaders import PyPDFLoader\n",
    "    llm_loader = PyPDFLoader(path)\n",
    "    pages = llm_loader.load_and_split()\n",
    "    \n",
    "    if withImages:\n",
    "        doc = ArixParse(pdf_path=path).parse()\n",
    "        images_path = Path(outputdir) / \"images\"\n",
    "        images_path.mkdir(exist_ok=True)\n",
    "\n",
    "        image_counter = 0\n",
    "        for element, level in doc.iterate_items():\n",
    "            if isinstance(element, PictureItem):\n",
    "                image_counter += 1\n",
    "                img = element.get_image(doc)\n",
    "                if img:\n",
    "                    img_path = images_path / f\"figure_{image_counter}.png\"\n",
    "                    img.save(img_path, \"PNG\")\n",
    "    return pages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8afbc35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA is not available in the system. Fall back to 'CPU'\n",
      "CUDA is not available in the system. Fall back to 'CPU'\n"
     ]
    }
   ],
   "source": [
    "pages = parsePDF(\"paper.pdf\", outputdir=\"output\", withImages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df650ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Contents\\n1 Introduction 3\\n2 Related Works 4\\n2.1 Typical Vision Encoders in VLMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n2.2 End-to-end OCR Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n3 Methodology 5\\n3.1 Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n3.2 DeepEncoder . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n3.2.1 Architecture of DeepEncoder . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n3.2.2 Multiple resolution support . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n3.3 The MoE Decoder . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3.4 Data Engine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3.4.1 OCR 1.0 data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3.4.2 OCR 2.0 data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n3.4.3 General vision data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.4.4 Text-only data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.5 Training Pipelines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n3.5.1 Training DeepEncoder . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\n3.5.2 Training DeepSeek-OCR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\n4 Evaluation 10\\n4.1 Vision-text Compression Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\n4.2 OCR Practical Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n4.3 Qualitative Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n4.3.1 Deep parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n4.3.2 Multilingual recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n4.3.3 General vision understanding . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n5 Discussion 18\\n6 Conclusion 19\\n2'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[1].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c2b973",
   "metadata": {},
   "source": [
    "## 2. Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c15866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\",\n",
    "    chunk_size=300,  # configurable variable\n",
    "    length_function = len,\n",
    "    chunk_overlap=50, # configurable variable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1928bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "metadatas = []\n",
    "for page in pages:\n",
    "    documents.append(page.page_content)\n",
    "    metadatas.append(page.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "771844d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.create_documents(documents, metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ed6923a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf01aa3",
   "metadata": {},
   "source": [
    "## 3. Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35dd2622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "env_values = dotenv_values('app.env')\n",
    "cohere_api_key = env_values['COHERE_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48f8d76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheha\\AppData\\Local\\Temp\\ipykernel_24572\\2180575093.py:2: LangChainDeprecationWarning: The class `CohereEmbeddings` was deprecated in LangChain 0.0.30 and will be removed in 1.0. An updated version of the class exists in the `langchain-cohere package and should be used instead. To use it run `pip install -U `langchain-cohere` and import as `from `langchain_cohere import CohereEmbeddings``.\n",
      "  embedding_llm = CohereEmbeddings(cohere_api_key=cohere_api_key, user_agent=\"langchain\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings.cohere import CohereEmbeddings\n",
    "embedding_llm = CohereEmbeddings(cohere_api_key=cohere_api_key, user_agent=\"langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c37f2a",
   "metadata": {},
   "source": [
    "## 4. Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68c8d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vector_db = FAISS.from_documents(chunks, embedding_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1326706",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"VLM\"\n",
    "similar_docs = vector_db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bee71cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VITDet\n",
      "VIT\n",
      "Down-\n",
      "sample VIT\n",
      "LLM\n",
      "VIT\n",
      "(navit) LLM\n",
      "Down-\n",
      "sample\n",
      "LLM\n",
      "Down-\n",
      "sample\n",
      "Vary/DeepSeekVL/...\n",
      "[× ] unsupported pipeline  parallel   \n",
      "1024\n",
      "1024\n",
      "224224\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "[× ] unsupported extreme resolution   \n",
      "[× ] low native resolution  [× ] overly small patches\n",
      "InternVL series/\n",
      "DeepSeekVL2/...\n",
      "usua\n"
     ]
    }
   ],
   "source": [
    "print(similar_docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "309d64ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_dir = \"faiss_vector_data\"\n",
    "vector_db.save_local(save_to_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
